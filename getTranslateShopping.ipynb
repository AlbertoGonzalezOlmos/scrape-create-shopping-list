{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88391b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge gdk-pixbuf\n",
    "# pip install pango\n",
    "# pip install pycairo\n",
    "\n",
    "######## ALTERNATIVE with annoying watermark\n",
    "# pip install aspose-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fb26146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import ast\n",
    "# import md2pdf\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "def load_api_key(config_file):\n",
    "    with open(config_file) as f:\n",
    "        config = json.load(f)\n",
    "    client = OpenAI(api_key=config['api_key'])\n",
    "    return client\n",
    "\n",
    "def get_text_files(directory):\n",
    "    list_of_files = glob.glob(os.path.join(directory, '*.txt'))\n",
    "    latest_file, file_name = [\"\",\" \"]\n",
    "    if len(list_of_files) > 0:\n",
    "        latest_file = max(list_of_files, key=os.path.getctime)\n",
    "        full_name = os.path.basename(latest_file)\n",
    "        file_name = os.path.splitext(full_name)\n",
    "    return latest_file, file_name[0]\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    return content\n",
    "\n",
    "def output_directories(path,name,extension):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    n_files = \"\"\n",
    "    # n_files = len(get_text_files(path))\n",
    "    # n_files = n_files + 1\n",
    "    # if n_files < 10:\n",
    "    #     n_files = \"0\" + str(n_files)\n",
    "    # else:\n",
    "    #     n_files = str(n_files)\n",
    "    nameFile = name + n_files + extension\n",
    "    return(path + nameFile)\n",
    "\n",
    "# from __future__ import print_function\n",
    "\n",
    "def find_values(id, json_repr):\n",
    "    results = []\n",
    "\n",
    "    def _decode_dict(a_dict):\n",
    "        try:\n",
    "            results.append(a_dict[id])\n",
    "        except KeyError:\n",
    "            pass\n",
    "        return a_dict\n",
    "\n",
    "    json.loads(json_repr, object_hook=_decode_dict) # Return value ignored.\n",
    "    return results\n",
    "\n",
    "directory = \"./mealPlans/\"\n",
    "config_file = \"config.json\"\n",
    "\n",
    "client = load_api_key(config_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d6968ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_completion(prompt, client, model=\"gpt-4\", temperature=0, ):\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": 'You are a inventory expert in a grocery store'},\n",
    "                {\"role\": \"user\", \"content\": prompt}]\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    # response = completion.model_dump_json(indent=2)\n",
    "    return completion.choices[0].message.content # message[\"content\"]\n",
    "\n",
    "\n",
    "\n",
    "def get_completion_from_messages(messages, client, model=\"gpt-4\", temperature=0.3):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c08af1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "yes?\n",
      "0\n",
      "Thai soup with shrimp\n",
      "\n",
      "INGREDIENTS\n",
      "\n",
      "2 regular onions\n",
      "2 bell peppers\n",
      "3 cloves of garlic\n",
      "2 tbsp oil for frying\n",
      "2 tbsp curry or red curry paste\n",
      "7 dl water\n",
      "1 bouillon cube\n",
      "400 ml coconut milk\n",
      "1 tbsp paprika\n",
      "1 tbsp sugar\n",
      "chili powder to taste\n",
      "1 dl rice\n",
      "salt and pepper\n",
      "200 g shrimp, thawed\n",
      "\n",
      "One pot noodles with egg and vegetables\n",
      "\n",
      "INGREDIENTS\n",
      "\n",
      "2 cloves of garlic\n",
      "1 bell pepper\n",
      "1 bunch of spring onions\n",
      "3 carrots\n",
      "300 g cabbage white cabbage or pointed cabbage\n",
      "1 tbsp oil\n",
      "2 tsp ginger possibly freshly grated\n",
      "250 g whole grain noodles\n",
      "9 dl water\n",
      "1 bouillon cube\n",
      "4 eggs\n",
      "salt and pepper\n",
      "Sauce\n",
      "3 tbsp lime juice\n",
      "2 tbsp soy sauce\n",
      "4 tsp tahini or peanut butter\n",
      "2 tsp sugar\n",
      "1 tsp garlic powder\n",
      "\n",
      "Spicy chicken in a dish\n",
      "\n",
      "INGREDIENTS\n",
      "\n",
      "400 g chicken breast, thigh fillet or inner fillet\n",
      "oil for frying\n",
      "2 bell peppers\n",
      "2 regular onions\n",
      "2 cloves of garlic\n",
      "1 can chopped tomatoes\n",
      "1 pack buko spicy cheese\n",
      "250 ml oma cooking cream 4%\n",
      "2 tbsp paprika\n",
      "1 bouillon cube\n",
      "salt and pepper\n",
      "Side dish\n",
      "1 pack cauliflower rice, 350 g\n",
      "300 g rice or coarse bulgur\n",
      "\n",
      "Bean Burrito\n",
      "\n",
      "INGREDIENTS\n",
      "\n",
      "2 onions\n",
      "2 cloves of garlic\n",
      "2 tsp oil for frying\n",
      "2 red bell peppers\n",
      "2 cans kidney beans\n",
      "1 can chopped tomatoes\n",
      "70 g tomato puree\n",
      "1 tbsp balsamic vinegar\n",
      "0.5 tsp cumin\n",
      "1 tsp paprika\n",
      "chili or cayenne pepper to taste\n",
      "salt and pepper\n",
      "6 whole grain tortillas\n",
      "75 g grated cheddar\n",
      "\n",
      "Lobster soup with baked cod\n",
      "\n",
      "INGREDIENTS\n",
      "\n",
      "750 g lobster soup e.g. bornholm's\n",
      "225 g cod fillets\n",
      "1.5 dl water + a splash of lemon juice or white wine\n",
      "salt and pepper\n",
      "Side dish\n",
      "1 pack bread croutons with garlic\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "####### Ingredients  ############\n",
    "###################################\n",
    "# INPUT: Lists of Ingredients for each day in Danish.\n",
    "# OUTPUT: English translation of the lists of Ingredients for each day.\n",
    "\n",
    "# Setup new file of MealPlans\n",
    "\n",
    "text_file, file_name = get_text_files(directory)\n",
    "\n",
    "output_Ingredients_dir = \"./outputIngredients/\"\n",
    "outputIngredientsFile = output_directories(output_Ingredients_dir, file_name + \"_Ingredients_\",\".txt\")\n",
    "\n",
    "content = read_file(text_file)\n",
    "prompt = f\"\"\"\n",
    "Your task is to translate the  \n",
    "lists of ingredients from Danish to English.\\\n",
    "\n",
    "Lists of ingredients: \n",
    "\"\"\"\n",
    "\n",
    "content_prompt = f\"\"\"\n",
    "```{content}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt+content_prompt, client)\n",
    "\n",
    "print(response)\n",
    "\n",
    "#######################################\n",
    "#######################################\n",
    "# Saving results\n",
    "\n",
    "f = open(outputIngredientsFile, \"w\")\n",
    "f.write(response)\n",
    "f.close()  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "20be4f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Vegetables\": {\n",
      "    \"Onions\": 6,\n",
      "    \"Bell Peppers\": 7,\n",
      "    \"Garlic Cloves\": 9,\n",
      "    \"Spring Onions\": 1,\n",
      "    \"Carrots\": 3,\n",
      "    \"Cabbage\": 300,\n",
      "    \"Red Bell Peppers\": 2\n",
      "  },\n",
      "  \"Proteins\": {\n",
      "    \"Shrimp\": 200,\n",
      "    \"Eggs\": 4,\n",
      "    \"Chicken Breast\": 400,\n",
      "    \"Kidney Beans\": 2,\n",
      "    \"Cod Fillets\": 225\n",
      "  },\n",
      "  \"Grains\": {\n",
      "    \"Rice\": 1.3,\n",
      "    \"Whole Grain Noodles\": 250,\n",
      "    \"Whole Grain Tortillas\": 6,\n",
      "    \"Bread Croutons\": 1\n",
      "  },\n",
      "  \"Dairy\": {\n",
      "    \"Buko Spicy Cheese\": 1,\n",
      "    \"Oma Cooking Cream 4%\": 250,\n",
      "    \"Grated Cheddar\": 75\n",
      "  },\n",
      "  \"Canned Goods\": {\n",
      "    \"Coconut Milk\": 400,\n",
      "    \"Chopped Tomatoes\": 2,\n",
      "    \"Lobster Soup\": 750\n",
      "  },\n",
      "  \"Spices and Condiments\": {\n",
      "    \"Curry or Red Curry Paste\": 2,\n",
      "    \"Paprika\": 4,\n",
      "    \"Chili Powder\": \"to taste\",\n",
      "    \"Salt and Pepper\": \"to taste\",\n",
      "    \"Ginger\": 2,\n",
      "    \"Lime Juice\": 3,\n",
      "    \"Soy Sauce\": 2,\n",
      "    \"Tahini or Peanut Butter\": 4,\n",
      "    \"Garlic Powder\": 1,\n",
      "    \"Balsamic Vinegar\": 1,\n",
      "    \"Cumin\": 0.5,\n",
      "    \"Chili or Cayenne Pepper\": \"to taste\"\n",
      "  },\n",
      "  \"Oils\": {\n",
      "    \"Oil for Frying\": 6\n",
      "  },\n",
      "  \"Others\": {\n",
      "    \"Bouillon Cube\": 3,\n",
      "    \"Sugar\": 3,\n",
      "    \"Tomato Puree\": 70,\n",
      "    \"Cauliflower Rice Pack\": 1,\n",
      "    \"Water\": 17.5\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "####### ShoppingList  ############\n",
    "###################################\n",
    "# INPUT: Lists of Ingredients for each day in English.\n",
    "# OUTPUT: Json object containing a table with the ingredients \n",
    "#   grouped by category and the quantities added up.\n",
    "\n",
    "# Setup new file of ShoppingLists\n",
    "\n",
    "text_file, file_name = get_text_files(output_Ingredients_dir)\n",
    "\n",
    "output_ShoppingList_dir = \"./outputShoppingList/\"\n",
    "outputShoppingListFile = output_directories(output_ShoppingList_dir, file_name + \"_ShoppingList_\",\".json\")\n",
    "\n",
    "content = read_file(text_file)\n",
    "prompt = f\"\"\"\n",
    "Your task is to create a table with all the ingredients grouped\n",
    "by category and quantity.\\\n",
    "\n",
    "The output table must be in Json format.\\\n",
    "\n",
    "Your response must only be a Json object and nothing else.\\\n",
    "\n",
    "Lists of ingredients: \n",
    "\"\"\"\n",
    "\n",
    "content_prompt = f\"\"\"\n",
    "```{content}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt+content_prompt, client)\n",
    "\n",
    "print(response)\n",
    "\n",
    "#######################################\n",
    "#######################################\n",
    "# Saving results\n",
    "\n",
    "f = open(outputShoppingListFile, \"w\")\n",
    "f.write(response)\n",
    "f.close()  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "20dd3458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./outputShoppingList/w52_plan_Ingredients_03_ShoppingList_03.txt'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputShoppingListFile = './outputShoppingList/w52_plan_Ingredients_03_ShoppingList_03.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0974769e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alberto\\AppData\\Local\\Temp\\ipykernel_78112\\1894183376.py:4: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(outputShoppingListFile)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(outputShoppingListFile)\n\u001b[0;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\.conda\\envs\\scrapeSund\\Lib\\site-packages\\pandas\\io\\json\\_json.py:804\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\.conda\\envs\\scrapeSund\\Lib\\site-packages\\pandas\\io\\json\\_json.py:1014\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1012\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_object_parser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_lines(data_lines))\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1014\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_object_parser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mconvert_dtypes(\n\u001b[0;32m   1017\u001b[0m         infer_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype_backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype_backend\n\u001b[0;32m   1018\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\.conda\\envs\\scrapeSund\\Lib\\site-packages\\pandas\\io\\json\\_json.py:1040\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[1;34m(self, json)\u001b[0m\n\u001b[0;32m   1038\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1040\u001b[0m     obj \u001b[38;5;241m=\u001b[39m FrameParser(json, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mparse()\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\.conda\\envs\\scrapeSund\\Lib\\site-packages\\pandas\\io\\json\\_json.py:1173\u001b[0m, in \u001b[0;36mParser.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 1173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse()\n\u001b[0;32m   1175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1176\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\.conda\\envs\\scrapeSund\\Lib\\site-packages\\pandas\\io\\json\\_json.py:1366\u001b[0m, in \u001b[0;36mFrameParser._parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1362\u001b[0m orient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morient\n\u001b[0;32m   1364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m DataFrame(\n\u001b[1;32m-> 1366\u001b[0m         ujson_loads(json, precise_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecise_float), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1367\u001b[0m     )\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1369\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1370\u001b[0m         \u001b[38;5;28mstr\u001b[39m(k): v\n\u001b[0;32m   1371\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m ujson_loads(json, precise_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecise_float)\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1372\u001b[0m     }\n",
      "\u001b[1;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_json(outputShoppingListFile)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bc8276",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "###################################\n",
    "###################################\n",
    "####### CATEGORIES 01 #############\n",
    "######## 5 examples ###############\n",
    "###################################\n",
    "# INPUT: Extrapolation, 10 word max summary of texts.\n",
    "# OUTPUT: Categories, categorization of the extrapolated texts\n",
    "\n",
    "# Setup new file of categories\n",
    "output_Dir = \"./outputOnlyCategories/\"\n",
    "nameOutput_File = \"identifyOnlyCategories_\"\n",
    "output_File = output_directories(output_Dir,nameOutput_File)\n",
    "outputProgress_Dir = \"./progressOnlyCategories/\"\n",
    "outputProgress_File = output_directories(outputProgress_Dir,\"progressIdentifyOnlyCategories_\")\n",
    "\n",
    "# load extrapolation file\n",
    "pathFile = \"./outputExtrapolation/\"\n",
    "nameFile = \"extrapol*.txt\"\n",
    "list_of_files = glob.glob(pathFile + nameFile) # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "content = read_file(latest_file)\n",
    "\n",
    "####################################\n",
    "####################################\n",
    "# Prompt for Categories\n",
    "####################################\n",
    "####################################\n",
    "\n",
    "prompt01 = f\"\"\"\n",
    "\n",
    "Your task is to extract the topics discussed in a sequence of sentences delimited by <>. \n",
    "Each sentence is represented by a number. \\\n",
    "\n",
    "To perform the task follow these steps: \\\n",
    "- work out the topics discussed in the sentences. \\\n",
    "- reflect if you can find better topics to represent the sentences. \\\n",
    "- explain each topic in a concise way. \\\n",
    "\n",
    "Sentences: <{content}>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "temperature = 0\n",
    "model = 'gpt-4'\n",
    "response01 = get_completion(prompt01,model,temperature)\n",
    "response02 = get_completion(prompt01,model,temperature)\n",
    "response03 = get_completion(prompt01,model,temperature)\n",
    "\n",
    "prompt02 = f\"\"\"\n",
    "\n",
    "Follow these steps: \\\n",
    "- work out the topics delimited by \"\" best represent the sentences delimited by <>.\n",
    "- each sentence is represented by a number. \\\n",
    "- each topic is followed by an explanation. \\\n",
    "- use the explanation of the topic to find out which topics best represent the sentences. \\\n",
    "- explain each resulting topic in a concise way. \\\n",
    "- output the response as a python dictionary that contains the following \n",
    "key: topic name, and values: explanation. \\\n",
    "\n",
    "Sentences: <{content}>\\\n",
    "\n",
    "Topics: \" \\\n",
    "\n",
    "{response01} \\\n",
    "\n",
    "{response02} \\\n",
    "\n",
    "{response02} \\\n",
    "\n",
    "\"\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt02,model,temperature)\n",
    "\n",
    "print(response)\n",
    "\n",
    "#######################################\n",
    "#######################################\n",
    "# Saving results\n",
    "    \n",
    "f = open(output_File, \"w\")\n",
    "f.write(response)\n",
    "f.close()\n",
    "f = open(outputProgress_File, \"w\")\n",
    "f.write(\"temperature: \")\n",
    "f.write(str(temperature))\n",
    "f.write(\", model: \")\n",
    "f.write(model)\n",
    "f.write(\"\\n\")\n",
    "f.write(\"prompt01: \\n\")\n",
    "f.write(prompt01)\n",
    "f.write(\"prompt02: \\n\")\n",
    "f.write(prompt02)\n",
    "f.write(\"\\n\")\n",
    "f.write(\"response: \\n\")\n",
    "f.write(response)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95489f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Education System\": \"Covers the overall quality, funding, and curriculum of schools.\",\n",
      "  \"Teaching Methods\": \"Refers to the approaches and techniques used in classrooms, including engagement and flexibility.\",\n",
      "  \"Parental Feedback\": \"Represents the opinions and satisfaction of parents with the education system.\",\n",
      "  \"School Staff\": \"Addresses the stability, motivation, and qualifications of teachers and other school personnel.\",\n",
      "  \"Neighborhood Factors\": \"Discusses the impact of local population and neighborhood on school quality.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "###################################\n",
    "###################################\n",
    "####### CATEGORIES ################\n",
    "###################################\n",
    "###################################\n",
    "# INPUT: Extrapolation, 10 word max summary of texts.\n",
    "# OUTPUT: Categories, categorization of the extrapolated texts\n",
    "\n",
    "# Setup new file of categories\n",
    "output_Dir = \"./outputOnlyCategories/\"\n",
    "nameOutput_File = \"identifyOnlyCategories_\"\n",
    "output_File = output_directories(output_Dir,nameOutput_File)\n",
    "outputProgress_Dir = \"./progressOnlyCategories/\"\n",
    "outputProgress_File = output_directories(outputProgress_Dir,\"progressIdentifyOnlyCategories_\")\n",
    "\n",
    "# load extrapolation file\n",
    "pathFile = \"./outputExtrapolation/\"\n",
    "nameFile = \"extrapol*.txt\"\n",
    "list_of_files = glob.glob(pathFile + nameFile) # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "content = read_file(latest_file)\n",
    "\n",
    "####################################\n",
    "####################################\n",
    "# Prompt for Categories\n",
    "####################################\n",
    "####################################\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Your task is to extract the topics discussed in a sequence of sentences delimited by <>. \n",
    "Each sentence is represented by a number. \\\n",
    "\n",
    "To perform the task follow these steps: \\\n",
    "- work out the topics discussed in the sentences. \\\n",
    "- reflect if you can find better topics to represent the sentences. \\\n",
    "- explain each topic in a concise way. \\\n",
    "- output the response as a python dictionary that contains the following \n",
    "key: topic name, and values: explanation. \\\n",
    "\n",
    "Sentences: <{content}>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "temperature = 0\n",
    "model = 'gpt-4'\n",
    "response = get_completion(prompt,model,temperature)\n",
    "\n",
    "print(response)\n",
    "\n",
    "#######################################\n",
    "#######################################\n",
    "# Saving results\n",
    "    \n",
    "f = open(output_File, \"w\")\n",
    "f.write(response)\n",
    "f.close()\n",
    "f = open(outputProgress_File, \"w\")\n",
    "f.write(\"temperature: \")\n",
    "f.write(str(temperature))\n",
    "f.write(\", model: \")\n",
    "f.write(model)\n",
    "f.write(\"\\n\")\n",
    "f.write(\"prompt: \\n\")\n",
    "f.write(prompt)\n",
    "f.write(\"\\n\")\n",
    "f.write(\"response: \\n\")\n",
    "f.write(response)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6251f0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Education System\": [1, 3, 4, 5, 6, 10],\n",
      "  \"Teaching Methods\": [1, 6, 10],\n",
      "  \"Parental Feedback\": [2, 5],\n",
      "  \"School Staff\": [7, 8, 9, 11],\n",
      "  \"Neighborhood Factors\": [4]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "###################################\n",
    "###################################\n",
    "####### PAIRING  ##################\n",
    "###### EXTRAPOLATION ##############\n",
    "####### CATEGORIES ################\n",
    "###################################\n",
    "###################################\n",
    "# INPUT: Extrapolation and Categories.\n",
    "# OUTPUT: Index of which extrapolation best fits each category.\n",
    "\n",
    "# Setup new file of categories\n",
    "output_Dir = \"./outputPairing/\"\n",
    "nameOutput_File = \"pairingExtrapolCategory_\"\n",
    "output_File = output_directories(output_Dir,nameOutput_File)\n",
    "outputProgress_Dir = \"./progressPairingExtrapolCategory/\"\n",
    "outputProgress_File = output_directories(outputProgress_Dir,\"progressPairingExtrapolCategory_\")\n",
    "\n",
    "# load extrapolation file\n",
    "pathFile = \"./outputExtrapolation/\"\n",
    "nameFile = \"extrapol*.txt\"\n",
    "list_of_files = glob.glob(pathFile + nameFile) # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "contentExtrapolations = read_file(latest_file)\n",
    "\n",
    "# load categories file\n",
    "pathFile = \"./outputOnlyCategories/\"\n",
    "nameFile = \"*Only*.txt\"\n",
    "list_of_files = glob.glob(pathFile + nameFile) # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "contentCategories = read_file(latest_file)\n",
    "\n",
    "####################################\n",
    "####################################\n",
    "# Prompt for pairing \n",
    "#  extrapolations \n",
    "#       with\n",
    "#    categories\n",
    "####################################\n",
    "####################################\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Your task is to associate the sentences delimited by <> to a category from the python dictionary delimited by \"\". \\\n",
    "Associate the sentences to a category by using its explanation value of the python dictionary. \\\n",
    "Each sentence is represented by a number. \\\n",
    "\n",
    "To perform the task follow these steps: \\\n",
    "- use the provided explanations to cluster the sentences. \\\n",
    "- reflect on how the explanations explain the sentences. \\\n",
    "- use only the provided categories. \\\n",
    "- associate all the sentences. \\\n",
    "- one sentence can be associated with more than one category. \\\n",
    "- output the response as a python dictionary that contains the following \n",
    "key: category name, and value: sentence number. \\\n",
    "\n",
    "Sentences: <{contentExtrapolations}> \\\n",
    "\n",
    "Categories: \"{contentCategories}\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "temperature = 0\n",
    "model = 'gpt-4'\n",
    "response = get_completion(prompt,model,temperature)\n",
    "\n",
    "print(response)\n",
    "\n",
    "#######################################\n",
    "#######################################\n",
    "# Saving results\n",
    "    \n",
    "f = open(output_File, \"w\")\n",
    "f.write(response)\n",
    "f.close()\n",
    "f = open(outputProgress_File, \"w\")\n",
    "f.write(\"temperature: \")\n",
    "f.write(str(temperature))\n",
    "f.write(\", model: \")\n",
    "f.write(model)\n",
    "f.write(\"\\n\")\n",
    "f.write(\"prompt: \\n\")\n",
    "f.write(prompt)\n",
    "f.write(\"\\n\")\n",
    "f.write(\"response: \\n\")\n",
    "f.write(response)\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550eab41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
