{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88391b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge gdk-pixbuf\n",
    "# pip install pango\n",
    "# pip install pycairo\n",
    "\n",
    "######## ALTERNATIVE with annoying watermark\n",
    "# pip install aspose-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fb26146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import ast\n",
    "# import md2pdf\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "def load_api_key(config_file):\n",
    "    with open(config_file) as f:\n",
    "        config = json.load(f)\n",
    "    client = OpenAI(api_key=config['api_key'])\n",
    "    return client\n",
    "\n",
    "def get_text_files(directory):\n",
    "    list_of_files = glob.glob(os.path.join(directory, '*.txt'))\n",
    "    latest_file, file_name = [\"\",\" \"]\n",
    "    if len(list_of_files) > 0:\n",
    "        latest_file = max(list_of_files, key=os.path.getctime)\n",
    "        full_name = os.path.basename(latest_file)\n",
    "        file_name = os.path.splitext(full_name)\n",
    "    return latest_file, file_name[0]\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    return content\n",
    "\n",
    "def output_directories(path,name,extension):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    n_files = \"\"\n",
    "    # n_files = len(get_text_files(path))\n",
    "    # n_files = n_files + 1\n",
    "    # if n_files < 10:\n",
    "    #     n_files = \"0\" + str(n_files)\n",
    "    # else:\n",
    "    #     n_files = str(n_files)\n",
    "    nameFile = name + n_files + extension\n",
    "    return(path + nameFile)\n",
    "\n",
    "# from __future__ import print_function\n",
    "\n",
    "def find_values(id, json_repr):\n",
    "    results = []\n",
    "\n",
    "    def _decode_dict(a_dict):\n",
    "        try:\n",
    "            results.append(a_dict[id])\n",
    "        except KeyError:\n",
    "            pass\n",
    "        return a_dict\n",
    "\n",
    "    json.loads(json_repr, object_hook=_decode_dict) # Return value ignored.\n",
    "    return results\n",
    "\n",
    "directory = \"./mealPlans/\"\n",
    "config_file = \"config.json\"\n",
    "\n",
    "client = load_api_key(config_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d6968ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_completion(prompt, client, model=\"gpt-4\", temperature=0, ):\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": 'You are a inventory expert in a grocery store'},\n",
    "                {\"role\": \"user\", \"content\": prompt}]\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    # response = completion.model_dump_json(indent=2)\n",
    "    return completion.choices[0].message.content # message[\"content\"]\n",
    "\n",
    "\n",
    "\n",
    "def get_completion_from_messages(messages, client, model=\"gpt-4\", temperature=0.3):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c08af1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "yes?\n",
      "0\n",
      "Thai soup with shrimp\n",
      "\n",
      "INGREDIENTS\n",
      "\n",
      "2 regular onions\n",
      "2 bell peppers\n",
      "3 cloves of garlic\n",
      "2 tbsp oil for frying\n",
      "2 tbsp curry or red curry paste\n",
      "7 dl water\n",
      "1 bouillon cube\n",
      "400 ml coconut milk\n",
      "1 tbsp paprika\n",
      "1 tbsp sugar\n",
      "chili powder to taste\n",
      "1 dl rice\n",
      "salt and pepper\n",
      "200 g shrimp, thawed\n",
      "\n",
      "One pot noodles with egg and vegetables\n",
      "\n",
      "INGREDIENTS\n",
      "\n",
      "2 cloves of garlic\n",
      "1 bell pepper\n",
      "1 bunch of spring onions\n",
      "3 carrots\n",
      "300 g cabbage white cabbage or pointed cabbage\n",
      "1 tbsp oil\n",
      "2 tsp ginger possibly freshly grated\n",
      "250 g whole grain noodles\n",
      "9 dl water\n",
      "1 bouillon cube\n",
      "4 eggs\n",
      "salt and pepper\n",
      "Sauce\n",
      "3 tbsp lime juice\n",
      "2 tbsp soy sauce\n",
      "4 tsp tahini or peanut butter\n",
      "2 tsp sugar\n",
      "1 tsp garlic powder\n",
      "\n",
      "Spicy chicken in a dish\n",
      "\n",
      "INGREDIENTS\n",
      "\n",
      "400 g chicken breast, thigh fillet or inner fillet\n",
      "oil for frying\n",
      "2 bell peppers\n",
      "2 regular onions\n",
      "2 cloves of garlic\n",
      "1 can chopped tomatoes\n",
      "1 pack buko spicy cheese\n",
      "250 ml oma cooking cream 4%\n",
      "2 tbsp paprika\n",
      "1 bouillon cube\n",
      "salt and pepper\n",
      "Side dish\n",
      "1 pack cauliflower rice, 350 g\n",
      "300 g rice or coarse bulgur\n",
      "\n",
      "Bean Burrito\n",
      "\n",
      "INGREDIENTS\n",
      "\n",
      "2 onions\n",
      "2 cloves of garlic\n",
      "2 tsp oil for frying\n",
      "2 red bell peppers\n",
      "2 cans kidney beans\n",
      "1 can chopped tomatoes\n",
      "70 g tomato puree\n",
      "1 tbsp balsamic vinegar\n",
      "0.5 tsp cumin\n",
      "1 tsp paprika\n",
      "chili or cayenne pepper to taste\n",
      "salt and pepper\n",
      "6 whole grain tortillas\n",
      "75 g grated cheddar\n",
      "\n",
      "Lobster soup with baked cod\n",
      "\n",
      "INGREDIENTS\n",
      "\n",
      "750 g lobster soup e.g. bornholm's\n",
      "225 g cod fillets\n",
      "1.5 dl water + a splash of lemon juice or white wine\n",
      "salt and pepper\n",
      "Side dish\n",
      "1 pack bread croutons with garlic\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "####### Ingredients  ############\n",
    "###################################\n",
    "# INPUT: Lists of Ingredients for each day in Danish.\n",
    "# OUTPUT: English translation of the lists of Ingredients for each day.\n",
    "\n",
    "# Setup new file of MealPlans\n",
    "\n",
    "text_file, file_name = get_text_files(directory)\n",
    "\n",
    "output_Ingredients_dir = \"./outputIngredients/\"\n",
    "outputIngredientsFile = output_directories(output_Ingredients_dir, file_name + \"_Ingredients_\",\".txt\")\n",
    "\n",
    "content = read_file(text_file)\n",
    "prompt = f\"\"\"\n",
    "Your task is to translate the  \n",
    "lists of ingredients from Danish to English.\\\n",
    "\n",
    "Lists of ingredients: \n",
    "\"\"\"\n",
    "\n",
    "content_prompt = f\"\"\"\n",
    "```{content}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt+content_prompt, client)\n",
    "\n",
    "print(response)\n",
    "\n",
    "#######################################\n",
    "#######################################\n",
    "# Saving results\n",
    "\n",
    "f = open(outputIngredientsFile, \"w\")\n",
    "f.write(response)\n",
    "f.close()  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "20be4f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Vegetables\": {\n",
      "    \"Onions\": 6,\n",
      "    \"Bell Peppers\": 7,\n",
      "    \"Garlic Cloves\": 9,\n",
      "    \"Spring Onions\": 1,\n",
      "    \"Carrots\": 3,\n",
      "    \"Cabbage\": 300,\n",
      "    \"Red Bell Peppers\": 2\n",
      "  },\n",
      "  \"Proteins\": {\n",
      "    \"Shrimp\": 200,\n",
      "    \"Eggs\": 4,\n",
      "    \"Chicken Breast\": 400,\n",
      "    \"Kidney Beans\": 2,\n",
      "    \"Cod Fillets\": 225\n",
      "  },\n",
      "  \"Grains\": {\n",
      "    \"Rice\": 1.3,\n",
      "    \"Whole Grain Noodles\": 250,\n",
      "    \"Whole Grain Tortillas\": 6,\n",
      "    \"Bread Croutons\": 1\n",
      "  },\n",
      "  \"Dairy\": {\n",
      "    \"Buko Spicy Cheese\": 1,\n",
      "    \"Oma Cooking Cream 4%\": 250,\n",
      "    \"Grated Cheddar\": 75\n",
      "  },\n",
      "  \"Canned Goods\": {\n",
      "    \"Coconut Milk\": 400,\n",
      "    \"Chopped Tomatoes\": 2,\n",
      "    \"Lobster Soup\": 750\n",
      "  },\n",
      "  \"Spices and Condiments\": {\n",
      "    \"Curry or Red Curry Paste\": 2,\n",
      "    \"Paprika\": 4,\n",
      "    \"Chili Powder\": \"to taste\",\n",
      "    \"Salt and Pepper\": \"to taste\",\n",
      "    \"Ginger\": 2,\n",
      "    \"Lime Juice\": 3,\n",
      "    \"Soy Sauce\": 2,\n",
      "    \"Tahini or Peanut Butter\": 4,\n",
      "    \"Garlic Powder\": 1,\n",
      "    \"Balsamic Vinegar\": 1,\n",
      "    \"Cumin\": 0.5,\n",
      "    \"Chili or Cayenne Pepper\": \"to taste\"\n",
      "  },\n",
      "  \"Oils\": {\n",
      "    \"Oil for Frying\": 6\n",
      "  },\n",
      "  \"Others\": {\n",
      "    \"Bouillon Cube\": 3,\n",
      "    \"Sugar\": 3,\n",
      "    \"Tomato Puree\": 70,\n",
      "    \"Cauliflower Rice Pack\": 1,\n",
      "    \"Water\": 17.5\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "####### ShoppingList  ############\n",
    "###################################\n",
    "# INPUT: Lists of Ingredients for each day in English.\n",
    "# OUTPUT: Json object containing a table with the ingredients \n",
    "#   grouped by category and the quantities added up.\n",
    "\n",
    "# Setup new file of ShoppingLists\n",
    "\n",
    "text_file, file_name = get_text_files(output_Ingredients_dir)\n",
    "\n",
    "output_ShoppingList_dir = \"./outputShoppingList/\"\n",
    "outputShoppingListFile = output_directories(output_ShoppingList_dir, file_name + \"_ShoppingList_\",\".json\")\n",
    "\n",
    "content = read_file(text_file)\n",
    "prompt = f\"\"\"\n",
    "Your task is to create a table with all the ingredients grouped\n",
    "by category and quantity.\\\n",
    "\n",
    "The output table must be in Json format.\\\n",
    "\n",
    "Your response must only be a Json object and nothing else.\\\n",
    "\n",
    "Lists of ingredients: \n",
    "\"\"\"\n",
    "\n",
    "content_prompt = f\"\"\"\n",
    "```{content}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt+content_prompt, client)\n",
    "\n",
    "print(response)\n",
    "\n",
    "#######################################\n",
    "#######################################\n",
    "# Saving results\n",
    "\n",
    "f = open(outputShoppingListFile, \"w\")\n",
    "f.write(response)\n",
    "f.close()  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "20dd3458",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      2\u001b[0m outputShoppingListFile \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./outputShoppingList/w52_plan_Ingredients_03_ShoppingList_03.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m json_Shopping \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(outputShoppingListFile)\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\.conda\\envs\\scrapeSund\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_decoder\u001b[38;5;241m.\u001b[39mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\.conda\\envs\\scrapeSund\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_decode(s, idx\u001b[38;5;241m=\u001b[39m_w(s, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mend())\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\.conda\\envs\\scrapeSund\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "outputShoppingListFile = './outputShoppingList/w52_plan_Ingredients_03_ShoppingList_03.json'\n",
    "json_Shopping = json.loads(outputShoppingListFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0974769e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vegetables</th>\n",
       "      <th>Proteins</th>\n",
       "      <th>Grains</th>\n",
       "      <th>Dairy</th>\n",
       "      <th>Canned Goods</th>\n",
       "      <th>Spices and Condiments</th>\n",
       "      <th>Oils</th>\n",
       "      <th>Others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Onions</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bell Peppers</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garlic Cloves</th>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spring Onions</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carrots</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Vegetables  Proteins  Grains  Dairy  Canned Goods  \\\n",
       "Onions                6.0       NaN     NaN    NaN           NaN   \n",
       "Bell Peppers          7.0       NaN     NaN    NaN           NaN   \n",
       "Garlic Cloves         9.0       NaN     NaN    NaN           NaN   \n",
       "Spring Onions         1.0       NaN     NaN    NaN           NaN   \n",
       "Carrots               3.0       NaN     NaN    NaN           NaN   \n",
       "\n",
       "              Spices and Condiments  Oils  Others  \n",
       "Onions                          NaN   NaN     NaN  \n",
       "Bell Peppers                    NaN   NaN     NaN  \n",
       "Garlic Cloves                   NaN   NaN     NaN  \n",
       "Spring Onions                   NaN   NaN     NaN  \n",
       "Carrots                         NaN   NaN     NaN  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_json(outputShoppingListFile)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bc8276",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "###################################\n",
    "###################################\n",
    "####### CATEGORIES 01 #############\n",
    "######## 5 examples ###############\n",
    "###################################\n",
    "# INPUT: Extrapolation, 10 word max summary of texts.\n",
    "# OUTPUT: Categories, categorization of the extrapolated texts\n",
    "\n",
    "# Setup new file of categories\n",
    "output_Dir = \"./outputOnlyCategories/\"\n",
    "nameOutput_File = \"identifyOnlyCategories_\"\n",
    "output_File = output_directories(output_Dir,nameOutput_File)\n",
    "outputProgress_Dir = \"./progressOnlyCategories/\"\n",
    "outputProgress_File = output_directories(outputProgress_Dir,\"progressIdentifyOnlyCategories_\")\n",
    "\n",
    "# load extrapolation file\n",
    "pathFile = \"./outputExtrapolation/\"\n",
    "nameFile = \"extrapol*.txt\"\n",
    "list_of_files = glob.glob(pathFile + nameFile) # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "content = read_file(latest_file)\n",
    "\n",
    "####################################\n",
    "####################################\n",
    "# Prompt for Categories\n",
    "####################################\n",
    "####################################\n",
    "\n",
    "prompt01 = f\"\"\"\n",
    "\n",
    "Your task is to extract the topics discussed in a sequence of sentences delimited by <>. \n",
    "Each sentence is represented by a number. \\\n",
    "\n",
    "To perform the task follow these steps: \\\n",
    "- work out the topics discussed in the sentences. \\\n",
    "- reflect if you can find better topics to represent the sentences. \\\n",
    "- explain each topic in a concise way. \\\n",
    "\n",
    "Sentences: <{content}>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "temperature = 0\n",
    "model = 'gpt-4'\n",
    "response01 = get_completion(prompt01,model,temperature)\n",
    "response02 = get_completion(prompt01,model,temperature)\n",
    "response03 = get_completion(prompt01,model,temperature)\n",
    "\n",
    "prompt02 = f\"\"\"\n",
    "\n",
    "Follow these steps: \\\n",
    "- work out the topics delimited by \"\" best represent the sentences delimited by <>.\n",
    "- each sentence is represented by a number. \\\n",
    "- each topic is followed by an explanation. \\\n",
    "- use the explanation of the topic to find out which topics best represent the sentences. \\\n",
    "- explain each resulting topic in a concise way. \\\n",
    "- output the response as a python dictionary that contains the following \n",
    "key: topic name, and values: explanation. \\\n",
    "\n",
    "Sentences: <{content}>\\\n",
    "\n",
    "Topics: \" \\\n",
    "\n",
    "{response01} \\\n",
    "\n",
    "{response02} \\\n",
    "\n",
    "{response02} \\\n",
    "\n",
    "\"\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt02,model,temperature)\n",
    "\n",
    "print(response)\n",
    "\n",
    "#######################################\n",
    "#######################################\n",
    "# Saving results\n",
    "    \n",
    "f = open(output_File, \"w\")\n",
    "f.write(response)\n",
    "f.close()\n",
    "f = open(outputProgress_File, \"w\")\n",
    "f.write(\"temperature: \")\n",
    "f.write(str(temperature))\n",
    "f.write(\", model: \")\n",
    "f.write(model)\n",
    "f.write(\"\\n\")\n",
    "f.write(\"prompt01: \\n\")\n",
    "f.write(prompt01)\n",
    "f.write(\"prompt02: \\n\")\n",
    "f.write(prompt02)\n",
    "f.write(\"\\n\")\n",
    "f.write(\"response: \\n\")\n",
    "f.write(response)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95489f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Education System\": \"Covers the overall quality, funding, and curriculum of schools.\",\n",
      "  \"Teaching Methods\": \"Refers to the approaches and techniques used in classrooms, including engagement and flexibility.\",\n",
      "  \"Parental Feedback\": \"Represents the opinions and satisfaction of parents with the education system.\",\n",
      "  \"School Staff\": \"Addresses the stability, motivation, and qualifications of teachers and other school personnel.\",\n",
      "  \"Neighborhood Factors\": \"Discusses the impact of local population and neighborhood on school quality.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "###################################\n",
    "###################################\n",
    "####### CATEGORIES ################\n",
    "###################################\n",
    "###################################\n",
    "# INPUT: Extrapolation, 10 word max summary of texts.\n",
    "# OUTPUT: Categories, categorization of the extrapolated texts\n",
    "\n",
    "# Setup new file of categories\n",
    "output_Dir = \"./outputOnlyCategories/\"\n",
    "nameOutput_File = \"identifyOnlyCategories_\"\n",
    "output_File = output_directories(output_Dir,nameOutput_File)\n",
    "outputProgress_Dir = \"./progressOnlyCategories/\"\n",
    "outputProgress_File = output_directories(outputProgress_Dir,\"progressIdentifyOnlyCategories_\")\n",
    "\n",
    "# load extrapolation file\n",
    "pathFile = \"./outputExtrapolation/\"\n",
    "nameFile = \"extrapol*.txt\"\n",
    "list_of_files = glob.glob(pathFile + nameFile) # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "content = read_file(latest_file)\n",
    "\n",
    "####################################\n",
    "####################################\n",
    "# Prompt for Categories\n",
    "####################################\n",
    "####################################\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Your task is to extract the topics discussed in a sequence of sentences delimited by <>. \n",
    "Each sentence is represented by a number. \\\n",
    "\n",
    "To perform the task follow these steps: \\\n",
    "- work out the topics discussed in the sentences. \\\n",
    "- reflect if you can find better topics to represent the sentences. \\\n",
    "- explain each topic in a concise way. \\\n",
    "- output the response as a python dictionary that contains the following \n",
    "key: topic name, and values: explanation. \\\n",
    "\n",
    "Sentences: <{content}>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "temperature = 0\n",
    "model = 'gpt-4'\n",
    "response = get_completion(prompt,model,temperature)\n",
    "\n",
    "print(response)\n",
    "\n",
    "#######################################\n",
    "#######################################\n",
    "# Saving results\n",
    "    \n",
    "f = open(output_File, \"w\")\n",
    "f.write(response)\n",
    "f.close()\n",
    "f = open(outputProgress_File, \"w\")\n",
    "f.write(\"temperature: \")\n",
    "f.write(str(temperature))\n",
    "f.write(\", model: \")\n",
    "f.write(model)\n",
    "f.write(\"\\n\")\n",
    "f.write(\"prompt: \\n\")\n",
    "f.write(prompt)\n",
    "f.write(\"\\n\")\n",
    "f.write(\"response: \\n\")\n",
    "f.write(response)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6251f0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Education System\": [1, 3, 4, 5, 6, 10],\n",
      "  \"Teaching Methods\": [1, 6, 10],\n",
      "  \"Parental Feedback\": [2, 5],\n",
      "  \"School Staff\": [7, 8, 9, 11],\n",
      "  \"Neighborhood Factors\": [4]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "###################################\n",
    "###################################\n",
    "####### PAIRING  ##################\n",
    "###### EXTRAPOLATION ##############\n",
    "####### CATEGORIES ################\n",
    "###################################\n",
    "###################################\n",
    "# INPUT: Extrapolation and Categories.\n",
    "# OUTPUT: Index of which extrapolation best fits each category.\n",
    "\n",
    "# Setup new file of categories\n",
    "output_Dir = \"./outputPairing/\"\n",
    "nameOutput_File = \"pairingExtrapolCategory_\"\n",
    "output_File = output_directories(output_Dir,nameOutput_File)\n",
    "outputProgress_Dir = \"./progressPairingExtrapolCategory/\"\n",
    "outputProgress_File = output_directories(outputProgress_Dir,\"progressPairingExtrapolCategory_\")\n",
    "\n",
    "# load extrapolation file\n",
    "pathFile = \"./outputExtrapolation/\"\n",
    "nameFile = \"extrapol*.txt\"\n",
    "list_of_files = glob.glob(pathFile + nameFile) # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "contentExtrapolations = read_file(latest_file)\n",
    "\n",
    "# load categories file\n",
    "pathFile = \"./outputOnlyCategories/\"\n",
    "nameFile = \"*Only*.txt\"\n",
    "list_of_files = glob.glob(pathFile + nameFile) # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "contentCategories = read_file(latest_file)\n",
    "\n",
    "####################################\n",
    "####################################\n",
    "# Prompt for pairing \n",
    "#  extrapolations \n",
    "#       with\n",
    "#    categories\n",
    "####################################\n",
    "####################################\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Your task is to associate the sentences delimited by <> to a category from the python dictionary delimited by \"\". \\\n",
    "Associate the sentences to a category by using its explanation value of the python dictionary. \\\n",
    "Each sentence is represented by a number. \\\n",
    "\n",
    "To perform the task follow these steps: \\\n",
    "- use the provided explanations to cluster the sentences. \\\n",
    "- reflect on how the explanations explain the sentences. \\\n",
    "- use only the provided categories. \\\n",
    "- associate all the sentences. \\\n",
    "- one sentence can be associated with more than one category. \\\n",
    "- output the response as a python dictionary that contains the following \n",
    "key: category name, and value: sentence number. \\\n",
    "\n",
    "Sentences: <{contentExtrapolations}> \\\n",
    "\n",
    "Categories: \"{contentCategories}\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "temperature = 0\n",
    "model = 'gpt-4'\n",
    "response = get_completion(prompt,model,temperature)\n",
    "\n",
    "print(response)\n",
    "\n",
    "#######################################\n",
    "#######################################\n",
    "# Saving results\n",
    "    \n",
    "f = open(output_File, \"w\")\n",
    "f.write(response)\n",
    "f.close()\n",
    "f = open(outputProgress_File, \"w\")\n",
    "f.write(\"temperature: \")\n",
    "f.write(str(temperature))\n",
    "f.write(\", model: \")\n",
    "f.write(model)\n",
    "f.write(\"\\n\")\n",
    "f.write(\"prompt: \\n\")\n",
    "f.write(prompt)\n",
    "f.write(\"\\n\")\n",
    "f.write(\"response: \\n\")\n",
    "f.write(response)\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550eab41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
